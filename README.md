# Sistema Distribuido de Reconocimiento de Objetos con IA

**PrÃ¡ctica 04 - CC4P1 ProgramaciÃ³n Concurrente y Distribuida**

Sistema distribuido para el entrenamiento y detecciÃ³n de objetos en tiempo real utilizando YOLO v8 y mÃºltiples cÃ¡maras IP (RTSP).

---

## CaracterÃ­sticas Principales

- **Arquitectura Distribuida:** 3 servidores + 1 cliente comunicados mediante sockets puros TCP
- **DetecciÃ³n en Tiempo Real:** Procesamiento de video desde mÃºltiples cÃ¡maras simultÃ¡neamente
- **Modelo de IA:** YOLOv8 para reconocimiento de objetos
- **Concurrencia:** Uso de hilos (threads) para procesamiento paralelo
- **Protocolo Custom:** ComunicaciÃ³n mediante protocolo propio sin frameworks
- **Persistencia:** Almacenamiento de modelos entrenados y logs de detecciones
- **Interfaz GrÃ¡fica:** Cliente vigilante con Tkinter para monitoreo en tiempo real

---

## Arquitectura del Sistema

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                                                               â”‚
â”‚  CÃ¡maras RTSP  â†’  SERVIDOR VIDEO  â†’  SERVIDOR TESTEO        â”‚
â”‚    (1...C)         (Puerto 5000)      (Puerto 5002)          â”‚
â”‚                                              â†“                â”‚
â”‚                                     [Detecciones]            â”‚
â”‚                                              â†“                â”‚
â”‚                                    CLIENTE VIGILANTE         â”‚
â”‚                                        (Tkinter UI)          â”‚
â”‚                                                               â”‚
â”‚                    SERVIDOR ENTRENAMIENTO                    â”‚
â”‚                       (Puerto 5001)                          â”‚
â”‚                                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Componentes

1. **Servidor de Video** (`src/servidor_video/`)
   - Captura video desde C cÃ¡maras IP (RTSP)
   - Usa hilos para captura simultÃ¡nea
   - EnvÃ­a frames a servidor de testeo vÃ­a sockets TCP

2. **Servidor de Entrenamiento** (`src/servidor_entrenamiento/`)
   - Entrena modelos YOLO con datasets custom
   - Guarda modelos entrenados persistentemente
   - Responde a solicitudes de entrenamiento

3. **Servidor de Testeo** (`src/servidor_testeo/`)
   - Recibe frames del servidor de video
   - Aplica modelo YOLO para detectar objetos
   - Guarda imÃ¡genes y logs de detecciones
   - Notifica al cliente vigilante

4. **Cliente Vigilante** (`src/cliente_vigilante/`)
   - Interfaz grÃ¡fica (Tkinter)
   - Visualiza detecciones en tiempo real
   - Muestra historial con imÃ¡genes

---

## Requisitos del Sistema

### Software
- Python 3.8+
- OpenCV
- PyTorch
- Ultralytics YOLOv8
- Pillow (para GUI)
- Tkinter (generalmente incluido con Python)

### Hardware
- **MÃ­nimo:** CPU multi-core, 8GB RAM
- **Recomendado:** GPU NVIDIA con CUDA, 16GB RAM

### Red
- ConexiÃ³n LAN o WiFi
- Acceso a cÃ¡maras IP con protocolo RTSP
- Puertos 5000-5002 disponibles

---

## InstalaciÃ³n

### 1. Clonar/Descargar el Proyecto

```bash
cd PC4concurrentes
```

### 2. Crear Entorno Virtual (Recomendado)

```bash
python3 -m venv venv
source venv/bin/activate  # Linux/Mac
# o
venv\Scripts\activate  # Windows
```

### 3. Instalar Dependencias

```bash
pip install -r requirements.txt
```

**Nota:** La instalaciÃ³n de PyTorch puede requerir comandos especÃ­ficos segÃºn tu sistema.
Visita: https://pytorch.org/get-started/locally/

---

## ConfiguraciÃ³n

### 1. Configurar CÃ¡maras RTSP

Editar `config/config.json` y completar las URLs de las cÃ¡maras:

```json
{
  "camaras": {
    "cantidad": 3,
    "lista": [
      {
        "id": 1,
        "nombre": "Camara Entrada",
        "rtsp_url": "rtsp://usuario:password@192.168.1.100:554/stream1",
        "enabled": true
      },
      {
        "id": 2,
        "nombre": "Camara Pasillo",
        "rtsp_url": "rtsp://usuario:password@192.168.1.101:554/stream1",
        "enabled": true
      }
    ]
  }
}
```

**Formato RTSP:** `rtsp://usuario:password@IP:puerto/stream`

### 2. Configurar IPs de Servidores (Para Cluster)

Si ejecutas en mÃºltiples mÃ¡quinas, editar `config/config.json`:

```json
{
  "servidor_video": {
    "host": "0.0.0.0",  // Escucha en todas las interfaces
    "puerto": 5000
  },
  "servidor_testeo": {
    "host": "0.0.0.0",
    "puerto": 5002
  },
  "cliente_vigilante": {
    "servidor_testeo_host": "192.168.1.10",  // IP del servidor de testeo
    "servidor_testeo_puerto": 5002
  }
}
```

### 3. Verificar CÃ¡maras

Probar conexiÃ³n a cÃ¡maras:

```bash
python scripts/test_cameras.py
```

---

## PreparaciÃ³n del Dataset

### OpciÃ³n 1: Dataset COCO128 (Recomendado para Pruebas)

```bash
python scripts/download_dataset.py
# Seleccionar opciÃ³n 1
```

El dataset COCO128 contiene 80 clases de objetos comunes:
- Personas, vehÃ­culos, animales, objetos cotidianos

### OpciÃ³n 2: Dataset de Kaggle

Configurar Kaggle API:
1. Ir a https://www.kaggle.com/settings/account
2. Crear API token â†’ Descargar `kaggle.json`
3. Colocar en `~/.kaggle/kaggle.json` (Linux/Mac) o `C:\Users\<user>\.kaggle\` (Windows)

Descargar dataset:

```bash
python scripts/download_dataset.py
# Seleccionar opciÃ³n 2
# Ejemplo: ultralytics/coco128
```

### OpciÃ³n 3: Dataset Custom

```bash
python scripts/download_dataset.py
# Seleccionar opciÃ³n 3
# Seguir instrucciones para crear estructura
```

Estructura del dataset:
```
data/mi_dataset/
â”œâ”€â”€ images/
â”‚   â”œâ”€â”€ train/  <- ImÃ¡genes de entrenamiento
â”‚   â””â”€â”€ val/    <- ImÃ¡genes de validaciÃ³n
â”œâ”€â”€ labels/
â”‚   â”œâ”€â”€ train/  <- Etiquetas YOLO (.txt)
â”‚   â””â”€â”€ val/
â””â”€â”€ data.yaml   <- ConfiguraciÃ³n del dataset
```

---

## Uso del Sistema

### Orden de EjecuciÃ³n

**IMPORTANTE:** Iniciar en este orden:

#### 1. Servidor de Entrenamiento (Opcional - solo si vas a entrenar)

```bash
python src/servidor_entrenamiento/servidor_entrenamiento.py
```

#### 2. Servidor de Video

```bash
python src/servidor_video/servidor_video.py
```

Debe mostrar:
```
=== Servidor de Video ===
CÃ¡maras configuradas: 3
[CÃ¡mara 1] ConexiÃ³n exitosa
[CÃ¡mara 2] ConexiÃ³n exitosa
[CÃ¡mara 3] ConexiÃ³n exitosa
Servidor escuchando en puerto 5000
```

#### 3. Servidor de Testeo

```bash
python src/servidor_testeo/servidor_testeo.py
```

Debe mostrar:
```
=== Servidor de Testeo/DetecciÃ³n ===
Cargando modelo desde: models/mejor_modelo.pt
Modelo cargado exitosamente
Conectando al servidor de video: 127.0.0.1:5000
ConexiÃ³n exitosa
```

#### 4. Cliente Vigilante

```bash
python src/cliente_vigilante/cliente_vigilante.py
```

Se abrirÃ¡ la interfaz grÃ¡fica mostrando detecciones en tiempo real.

---

## Entrenar un Modelo

### 1. Preparar Dataset

Asegurarse de tener un dataset en formato YOLO con su `data.yaml`.

### 2. Iniciar Servidor de Entrenamiento

```bash
python src/servidor_entrenamiento/servidor_entrenamiento.py
```

### 3. Enviar Solicitud de Entrenamiento

Crear un script cliente o usar Python interactivo:

```python
import socket
import sys
sys.path.append('.')

from src.common.protocolo import Protocolo, TipoMensaje

# Conectar al servidor
sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)
sock.connect(('localhost', 5001))

# Enviar solicitud de entrenamiento
Protocolo.enviar_mensaje(sock, TipoMensaje.TRAIN_REQUEST, {
    'dataset_path': 'data/coco128/data.yaml',
    'epochs': 50
})

# Recibir respuesta
mensaje = Protocolo.recibir_mensaje(sock)
print(mensaje)

sock.close()
```

El modelo entrenado se guardarÃ¡ en `models/mejor_modelo.pt`.

---

## EjecuciÃ³n en Cluster (MÃºltiples PCs)

### ConfiguraciÃ³n

**PC 1 - Servidor de Video:**
```json
{
  "servidor_video": {
    "host": "0.0.0.0",  // Escuchar en todas las interfaces
    "puerto": 5000
  }
}
```

**PC 2 - Servidor de Testeo:**
```json
{
  "servidor_testeo": {
    "host": "0.0.0.0",
    "puerto": 5002
  }
}
```

En `servidor_testeo.py`, configurar IP del servidor de video:
```python
self.video_host = "192.168.1.10"  # IP de PC 1
```

**PC 3 - Cliente Vigilante:**
```json
{
  "cliente_vigilante": {
    "servidor_testeo_host": "192.168.1.20",  // IP de PC 2
    "servidor_testeo_puerto": 5002
  }
}
```

### Firewall

Abrir puertos en el firewall:

**Linux:**
```bash
sudo ufw allow 5000/tcp
sudo ufw allow 5001/tcp
sudo ufw allow 5002/tcp
```

**Windows:**
ConfiguraciÃ³n â†’ Firewall â†’ Reglas de entrada â†’ Nueva regla

---

## Estructura del Proyecto

```
PC4concurrentes/
â”œâ”€â”€ config/
â”‚   â””â”€â”€ config.json              # ConfiguraciÃ³n del sistema
â”œâ”€â”€ data/                        # Datasets
â”‚   â”œâ”€â”€ train/
â”‚   â””â”€â”€ test/
â”œâ”€â”€ models/                      # Modelos entrenados
â”‚   â””â”€â”€ mejor_modelo.pt
â”œâ”€â”€ detecciones/                 # ImÃ¡genes de detecciones
â”‚   â”œâ”€â”€ camara_1/
â”‚   â”œâ”€â”€ camara_2/
â”‚   â””â”€â”€ camara_3/
â”œâ”€â”€ logs/
â”‚   â””â”€â”€ detecciones.json         # Log de detecciones
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ common/                  # MÃ³dulos comunes
â”‚   â”‚   â”œâ”€â”€ protocolo.py         # Protocolo de comunicaciÃ³n
â”‚   â”‚   â””â”€â”€ utils.py             # Utilidades
â”‚   â”œâ”€â”€ servidor_video/          # Servidor de video
â”‚   â”‚   â””â”€â”€ servidor_video.py
â”‚   â”œâ”€â”€ servidor_entrenamiento/  # Servidor de entrenamiento
â”‚   â”‚   â””â”€â”€ servidor_entrenamiento.py
â”‚   â”œâ”€â”€ servidor_testeo/         # Servidor de testeo
â”‚   â”‚   â””â”€â”€ servidor_testeo.py
â”‚   â””â”€â”€ cliente_vigilante/       # Cliente vigilante
â”‚       â””â”€â”€ cliente_vigilante.py
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ download_dataset.py      # Descarga de datasets
â”‚   â””â”€â”€ test_cameras.py          # Prueba de cÃ¡maras
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ INTERPRETACION_PROYECTO.md
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## Protocolo de ComunicaciÃ³n

### Formato de Mensajes

Todos los mensajes siguen el formato:

```
[4 bytes: tamaÃ±o] [N bytes: mensaje JSON]
```

Estructura del mensaje JSON:
```json
{
  "tipo": "FRAME",
  "timestamp": "2025-11-25T14:30:25.123456",
  "datos": {
    "camera_id": 1,
    "frame_data": "<base64_encoded_image>",
    ...
  }
}
```

### Tipos de Mensajes

| Tipo | DescripciÃ³n |
|------|-------------|
| `FRAME` | Frame de video (Video â†’ Testeo) |
| `DETECTION` | DetecciÃ³n de objeto (Testeo â†’ Vigilante) |
| `TRAIN_REQUEST` | Solicitud de entrenamiento |
| `TRAIN_COMPLETE` | Entrenamiento completado |
| `MODEL_READY` | Modelo listo para usar |
| `GET_DETECTIONS` | Solicitar historial |
| `ACK` | ConfirmaciÃ³n |
| `ERROR` | Error |

### Ejemplo: DetecciÃ³n

```json
{
  "tipo": "DETECTION",
  "timestamp": "2025-11-25T14:30:25",
  "datos": {
    "camera_id": 1,
    "objeto": "perro",
    "confianza": 0.95,
    "bbox": [100, 150, 300, 400],
    "imagen_path": "detecciones/camara_1/20251125_143025.jpg",
    "fecha": "2025-11-25",
    "hora": "14:30:25"
  }
}
```

---

## CaracterÃ­sticas TÃ©cnicas

### Concurrencia

- **Servidor de Video:** 1 hilo por cÃ¡mara para captura simultÃ¡nea
- **Servidor de Testeo:** Pool de hilos para procesamiento paralelo (configurable)
- **SincronizaciÃ³n:** Uso de locks para acceso thread-safe a recursos compartidos

### Persistencia

- **Modelos:** Guardados en formato PyTorch (.pt)
- **Detecciones:** JSON con metadata + imÃ¡genes en disco
- **ConfiguraciÃ³n:** JSON para fÃ¡cil ediciÃ³n

### Seguridad

- **No incluye autenticaciÃ³n:** Implementar si se despliega en producciÃ³n
- **RTSP:** Usar credenciales fuertes para cÃ¡maras
- **Red:** Ejecutar en red privada/VPN

---

## SoluciÃ³n de Problemas

### Error: No se puede conectar a la cÃ¡mara

- Verificar URL RTSP
- Probar con VLC: `vlc rtsp://...`
- Verificar credenciales
- Revisar firewall/red

### Error: Modelo no encontrado

- Entrenar modelo primero o usar modelo base:
  ```python
  self.modelo = YOLO('yolov8n.pt')  # Modelo pre-entrenado
  ```

### Error: Puerto en uso

- Cambiar puerto en `config/config.json`
- O cerrar proceso que usa el puerto:
  ```bash
  lsof -i :5000  # Ver proceso
  kill -9 <PID>  # Terminar proceso
  ```

### Bajo FPS / Alto uso de CPU

- Reducir resoluciÃ³n de frames en config
- Reducir FPS de captura
- Usar modelo YOLO mÃ¡s ligero (yolov8n en lugar de yolov8x)
- Reducir nÃºmero de cÃ¡maras simultÃ¡neas

---

## Extensiones Futuras

- [ ] Soporte para mÃºltiples lenguajes (Java, C++)
- [ ] Entrenamiento distribuido (mÃºltiples nodos)
- [ ] Balanceo de carga automÃ¡tico
- [ ] Dashboard web (sin frameworks prohibidos)
- [ ] Notificaciones en tiempo real (email, SMS)
- [ ] AnÃ¡lisis de patrones de detecciÃ³n
- [ ] Exportar reportes PDF
- [ ] Soporte para mÃ¡s tipos de cÃ¡maras (USB, IP sin RTSP)

---

## TecnologÃ­as Utilizadas

- **Lenguaje:** Python 3.8+
- **Modelo IA:** YOLOv8 (Ultralytics)
- **VisiÃ³n Computacional:** OpenCV
- **Deep Learning:** PyTorch
- **GUI:** Tkinter
- **ComunicaciÃ³n:** Sockets TCP puros (sin frameworks)
- **Concurrencia:** threading (hilos)
- **Formato de Datos:** JSON
- **Protocolo de Video:** RTSP

---

## Restricciones Cumplidas

âœ… **Sockets puros** - No uso de WebSocket, Socket.IO, frameworks
âœ… **RTSP** - Protocolo estÃ¡ndar para cÃ¡maras IP
âœ… **Hilos** - Concurrencia con threading
âœ… **Distribuido** - Arquitectura multi-nodo
âœ… **Persistencia** - Modelos y detecciones guardadas
âœ… **N clases** - Configurable (COCO: 80 clases)
âœ… **C cÃ¡maras** - Configurable (limitado por hardware)
âœ… **Cluster** - Ejecutable en LAN/WiFi

---

## Autores

**Curso:** CC4P1 ProgramaciÃ³n Concurrente y Distribuida
**PrÃ¡ctica:** 04 - 2025-II
**Fecha:** Noviembre 2025

---

## Licencia

Este proyecto es parte de una prÃ¡ctica acadÃ©mica.

---

## Referencias

- [Ultralytics YOLOv8](https://docs.ultralytics.com/)
- [OpenCV Documentation](https://docs.opencv.org/)
- [COCO Dataset](https://cocodataset.org/)
- [RTSP Protocol](https://en.wikipedia.org/wiki/Real_Time_Streaming_Protocol)
- [Python Socket Programming](https://docs.python.org/3/library/socket.html)

---

## Soporte

Para problemas o preguntas:
1. Revisar este README
2. Consultar `docs/INTERPRETACION_PROYECTO.md`
3. Verificar logs de los servidores
4. Probar componentes individualmente

**Â¡Ã‰xito con el proyecto!** ğŸš€
